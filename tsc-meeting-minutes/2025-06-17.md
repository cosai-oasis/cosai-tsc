# CoSAI TSC meeting

## 17 June 2025

**Present:**  J.R. Rao (IBM),  Andre Elizondo (Wiz), Matt Maloney (Cohere), Josiah Hagen (TrendMicro), Akila Srinivasan (Anthropic), Michael Scovetta (Microsoft), Sean Lee (Intel), Daniel Riedel (GenLab), Dan Mellen (EY),

**Regrets:**  
Daniel Rohrer (NVIDIA), Dustin Kirkland (Chainguard), Eoin Wickens (Hidden Layer), Ian Brelinsky (OpenAI), Joshua Chou (PayPal),  Matt Saner (Amazon), Omar Santos (Cisco), Peng Ning (Google), Rudy Lai (Snyk), Sean Morgan (Protect AI),

**Guests:** Claudia Rauch (OASIS), Ingrid Reis-Glass (OASIS), Sarah Novotny (WS4 co-lead), Jay White (WS1 co-lead), Kelly Cullinane (OASIS), Vinay Bansal (WS2 co-lead, Cisco alternate), Juliana Ball (MC co-hair), David LaBianca (PGB co-chair), Ian Molloy (WS4 co-lead)

*Quorum: 19 TSC members, 10 needed for quorum*

### Agenda

* Security Principles for Agents: see [document](https://docs.google.com/document/d/1OwpCO83lkKlms-J2RCIzQTbH9C-4t3Dk4j_kqq7p6Q4/edit?tab=t.0#heading=h.brjjwcro3bcw) started by David LaBianca, with comments from some TSC members for discussion  
* Shared Framework Responsibility [RFC](https://github.com/cosai-oasis/ws3-ai-risk-governance/issues/10) for Workstream 3, to be presented by Ian  
* Any other business?

### Notes

* **Security Principles for Agents Discussion**  
  * David introduced the [Agentic Security Principles document](https://docs.google.com/document/d/1OwpCO83lkKlms-J2RCIzQTbH9C-4t3Dk4j_kqq7p6Q4/edit?usp=sharing), continued discussion from the  previous TSC meeting, emphasizing the "why" behind it and its potential for external communication. The document's structure now focuses on principles such as human-centric governance and control, purpose-bound and risk-constrained operation, actionable transparency, and aligned operator objectives. David invited questions and feedback, particularly from those who hadn't yet contributed.  
  * Daniel raised a question about the separation and independent observability of agentic systems, especially regarding LLMs potentially communicating in ways that might not be understood, posing a governance and trust challenge. David suggested this could be addressed by strengthening the "actionable transparency and observability" principle to ensure the ability to review agent-to-agent interaction.  
* **Enterprise Goals and AI Integration**  
  * J.R. provided feedback on the goals section of the security principles document, suggesting a top-down approach starting with enterprise goals related to both "business as usual" and AI-driven outcomes, such as security, privacy, compliance, business continuity, brand protection, AI governance, supply chain security, and competitive advantage. He proposed structuring principles around what agents can do, cannot do, and must do, providing examples related to identity and access and privacy by design.  
* **Privacy and Data Retention in Agentic Systems**  
  * Daniel highlighted the tension between the desire to retain user information for better inference and the need to preserve privacy in agentic systems. David countered that assuming a universal approach to data retention might be inaccurate, as different enterprises will have different needs and risk tolerances. J.R. noted the opportunity to define what is secure regarding data handling, possibly on a use-case basis.  
* **Defining "Agentic System"**   
  * Sarah questioned the definition of "agentic systems" in the context of the principles, asking if this refers to protocols, frameworks, operators, or users. David agreed on the terminology issue, stating his current understanding of "agentic system" includes people, processes, things, technology, and protocols – the entire system. He acknowledged the need for a definitive document on terminology.  
* **"Alignment" vs. "Critical Safety"**   
  * Sarah expressed concern about the term "alignment," suggesting it anthropomorphizes AI. She suggested using "critical safety" framing instead, drawing parallels to safety-approved software in other industries. Jason's earlier comment on alignment for specific applications was noted, suggesting a potential difference in understanding the term.  
  * Andre sought clarification on whether the focus should remain on security or if the scope has expanded to include safety. David affirmed the general goal is to stay within the security domain, incorporating other elements only when required, referencing Jason's point about the need to trust the underlying system similar to trusting an employee.  
* **Human in the Loop Considerations**   
  * Michael raised concerns about "alert fatigue" if systems heavily rely on human intervention before actions, potentially leading to users approving actions without proper review, a known failure mode in security. David clarified that the intent is not to mandate "human in the loop" for every transaction but to ensure appropriate review mechanisms based on the specific workflow and risk context.  
* **Trust, Control, and Malicious Agents**  
  * Ian expressed discomfort with terms like "alignment" and "human operators" without specific context, referencing Jason's analogy of trusting an LLM like an employee. Ian highlighted the importance of constraining agents, assuming potential malicious intent, drawing parallels to insider threat controls. David agreed on the need for controls beyond just "trusting" the AI, comparing it to the need for background checks for employees but acknowledged the complexity of finding the right approach.  
* **Provenance and Supply Chain Security**   
  * Josiah pointed out the lack of emphasis on provenance, bill of materials, and supply chain, which he considers a form of "background check" for AI components. Josiah echoed concerns about venturing into safety territory.  
* **Next Steps for Security Principles**  
  * J.R. proposed that Sarah and Ian take the lead on progressing the document, with support from Akila and J.R., to address the issues raised in today’s meeting and produce the next version before the next meeting. This was agreed upon by the involved parties.  
  * J.R. emphasized the time-sensitive nature of the security principles, aiming for a release date in time for Aspen (July 15-18) as a set of agreed-upon principles endorsed by CoSAI. J.R. stressed the rapid pace of the field and the importance of aiming for the Aspen deadline.  
* **Shared Responsibility Model for AI**   
  * Ian provided background on [the active GitHub issue for this topic](https://github.com/cosai-oasis/ws3-ai-risk-governance/issues/10), which originated from discussions within the AI Alliance, highlighting the need for clarity on responsibilities across the AI stack (model provider, infrastructure provider, agentic middleware, etc.) and for the actions of deployed AI models and agents. David posed to the TSC whether this is work CoSAI should undertake and where it should reside, noting the current lack of clear examples beyond Azure's model. Andre emphasized the need to define the desired outcome (e.g., a blog post) and be aware of ongoing maintenance.  
* **Workstream 3 Status**  
  * J.R. noted the RFC's current location under WS3 and inquired about the workstream's current engagement level and capacity to take on this work, given David's multiple roles. David indicated that WS3 has faced challenges in defining its mission but believes a call for action on this topic could generate engagement. They also mentioned a pending co-lead nomination for WS3. J.R. suggested an offline discussion with David, Akila, and Omar to better understand WS3 and the path forward for the shared responsibility matrix, with a TSC discussion and potential resolution planned for the following week.  
  * Josiah asked Ian for more context on the AI Alliance's work on the shared responsibility model. Ian explained that the AI Alliance had lower-than-desired attendance, which was part of the reason for bringing the discussion to CoSAI, expecting broader participation.

### Next Steps and Action Items

* Daniel will propose a word, phrase, or positioning on the separation of agentic systems for observability in the security principles document.  
* Sarah and Ian will revise the security principles document this week, addressing the discussed issues to create the next version.  
* J.R. and Akila will schedule a discussion with David on Friday, potentially joined by Omar, to understand more about WS3 and the shared responsibility matrix.


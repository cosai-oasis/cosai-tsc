# CoSAI TSC Meeting -- DRAFT

# Date: 29 July 2025

**Present:**  Josiah Hagen (TrendMicro), J.R. Rao (IBM), Andre Elizondo (Wiz), Akila Srinivasan (Anthropic), Joshua Chou (PayPal), Michael Scovetta (Microsoft), Matt Maloney (Cohere), Omar Santos (Cisco), Daniel Rohrer (NVIDIA \- joined 30min in), 

**Regrets:**  
Dan Mellen (EY), Daniel Riedel (GenLab), Dustin Kirkland (Chainguard), Eoin Wickens (Hidden Layer), Ian Brelinsky (OpenAI),  Matt Saner (Amazon), Peng Ning (Google), Rudy Lai (Snyk), Sean Lee (Intel), Sean Morgan (Protect AI),

**Guests:** Claudia Rauch (OASIS), Ingrid Reis-Glass (OASIS), Kelly Cullinane (OASIS), Sarah Novotny (WS4 co-lead), David LaBianca (PGB co-chair, Google alternate), Jay White (WS1 co-lead), Vinay Bansal (WS2 co-lead), Juliana Ball (MC co-lead), Ian Molloy (WS4 co-lead \- joined 30min in)

*Quorum: 19 TSC members, 10 needed for quorum*

### Agenda

* Status of P0 Initiatives:  
  * Signing and Attestation of Models  
  * Incident Response  
  * MCP Security  
* Any other business?  
  * Defcon/Blackhat presence  
  * Marketing plans and discussion on feedback loop from our public presence

## Notes

* **Last Week's Presentation Debrief**  
  *  J.R. initiated a debrief of the previous week's presentation, thanking David for anchoring the call. David summarized that two policy staff and one tech staff from NCSC provided an overview of their implementation approach, emphasizing engagement and future focus.  
  * Akila inquired if the NCSC presentation changed the group's perspective or solidified existing plans. David stated that the NCSC clarified their view of standards work as a minimum required control set, a perspective that resonated with the group's own thinking. Sarah found it reassuring to hear the emphasis on reiterating standard cybersecurity practices and noted the connection between AI, agentic AI, and cyber-physical systems.  
  * David also highlighted the NCSC's emphasis on education as a significant requirement for workforce enablement.  
* **Volunteer Reviewers for WS2 Paper Needed**  
  * J.R. addressed Vinay's request for volunteers to review the next WS2 Incident Response paper, noting a lack of immediate responses from the wider TSC. Akila suggested asking the larger TSC group in Slack and involving other workstream leads to encourage volunteers, emphasizing the benefit of external reviewers to avoid bias in the final editorial review.  
  * Michael volunteered to review the paper.  
* **Model Signing Paper Update**   
  * Andre provided an update on the P0 model signing paper from WS1, stating that progress is going well, with a focus on clarifying consumer definitions and creating visuals. WS1 is transitioning intoediting mode, aiming for a rough edited draft by the end of the current week, with a version to share with the TSC for approval in the first or second week of August.  
  * Akila asked if there was substantial disagreement within the working group regarding the applicability of the model signing paper. Andre, Matt, and Jay confirmed a unified consensus, noting that participants from several big companies and organizations like Google, OpenSSF, and Nvidia are already heavily invested in signing workflows. Jay explained that the paper established a practical foundation, focusing on streamlining the process. Matt added that the paper aims to be practical and approachable, with a teaser for future maturity levels to encourage continued engagement.  
* **Model Vulnerabilities Standard**  
  * Andre mentioned a parallel effort within the workstream to propose a standard for defining model vulnerabilities and addressing gaps in current practices, such as inconsistent CVE usage. This effort is intentionally receiving less focus until the signing paper is released.  
* **Addressing Concerns of Major Model Creators**   
  * J.R. raised a question about the perspective of major model creators on the proposed model signing guidance particularly concerning models provided as a service. Andre acknowledged that there isn't active involvement from companies like OpenAI or Anthropic in the workstream.   
  * Akila suggested that the document should define when a model needs to be signed, potentially at the point of distribution to cloud providers or directly to enterprise customers, to provide confidence in model integrity.  
* **Scope of Model Signing Paper**  
  * Andre explained that the paper focuses on immediate problems like artifact integrity and tamper detection, without delving into every part of the process or specific SLSA levels. David suggested that the scope should focus on the moment a company provides a model for use, either internally or externally, outside of the foundational research realm. He emphasized that the paper should not reinvent the wheel but learn from previous experiences like SLSA.  
* **Future Content and Blog Posts**   
  * Andre discussed capturing more focused ideas for future content, such as blog posts or short white papers, to address specific use cases like model serving providers.   
* **Industry Adoption and Platform Integration**   
  * David emphasized the importance of tying the papers to real-world implementation, hoping that groups within their membership would start publishing signatures in the manner described. Ian added that automating signing into pipelines is difficult, and ease of verification is key, with a focus on OIDC-based signatures.  
* **Engaging Model Registries and Platforms**  
  *  J.R. raised the importance of engaging model registries like Hugging Face to apprise them of the proposed implementation and gauge their support for adoption, potentially through features like badges or model cards. Andre pointed out that mandating signing is unlikely. Daniel highlighted the challenge of adoption for platforms like Hugging Face due to their scale and diverse audiences. Andre inquired about engaging with Hugging Face directly and inviting them to CoSAI.  David suggested re-engaging Hugging Face and thinking about levels of adoption for platforms.  
* **Reference Code and Metadata Service**  
  *  J.R. inquired about developing reference code or artifacts to assist consumers with model verification. Andre proposed creating a public proof-of-concept to demonstrate the signing process in a workflow. He also briefly discussed the concept of a shared metadata service to advertise signed models, acknowledging it as a much larger initiative. Matt emphasized that the metadata service would improve accessibility by allowing users to quickly verify a model's signature without downloading large files.  
* **AI Audience and Documentation**  
  * Daniel discussed the emerging need to publish documentation and guidelines for AI agents who are increasingly producing code and integrations. Akila expanded on this, suggesting that future documentation should be "bot readable" and anticipate how AI agents will mediate information, raising questions about trust and safety in such a system.  
* **Next Steps and Meeting Schedule**   
  * J.R. concluded the discussion, acknowledging the depth covered on WS1 and the remaining questions regarding engagement with platforms and AI personas. He outlined future meeting plans, including updates from other workstreams and continued progress on MCP security.  
  * David noted that the meeting scheduled for next week would be cancelled due to Defcon.




